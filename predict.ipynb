{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71a76d0c",
   "metadata": {},
   "source": [
    "**Step 1: Get Historical Stock Price Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "516c43a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf   \n",
    "import pandas as pd  \n",
    "\n",
    "# Step 1: Download historical data for a specific stock (e.g., Apple)\n",
    "ticker = yf.Ticker(\"AAPL\")  # \"AAPL\" is the stock symbol for Apple Inc.\n",
    "\n",
    "# Step 2: Get 5 years of daily stock data\n",
    "stock_data = ticker.history(period=\"5y\")\n",
    "\n",
    "# Step 3: Show the first 5 rows of the data\n",
    "print(stock_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "325f493d",
   "metadata": {},
   "source": [
    "**Step 2: Add Economic Indicators**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c82fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas_datareader.data as web\n",
    "import datetime\n",
    "\n",
    "# Step 1: Define the date range (same as your stock data)\n",
    "start_date = datetime.datetime(2018, 1, 1)\n",
    "end_date = datetime.datetime.today()\n",
    "\n",
    "# Step 2: Fetch Consumer Price Index (CPI) - measures inflation\n",
    "cpi = web.DataReader('CPIAUCSL', 'fred', start_date, end_date)\n",
    "\n",
    "# Step 3: Fetch Federal Funds Rate (interest rate)\n",
    "interest_rate = web.DataReader('FEDFUNDS', 'fred', start_date, end_date)\n",
    "\n",
    "# Step 4: Fetch Unemployment Rate\n",
    "unemployment = web.DataReader('UNRATE', 'fred', start_date, end_date)\n",
    "\n",
    "# Step 5: Show the first few rows of each\n",
    "print(\"CPI:\")\n",
    "print(cpi.head())\n",
    "\n",
    "print(\"\\nInterest Rate:\")\n",
    "print(interest_rate.head())\n",
    "\n",
    "print(\"\\nUnemployment Rate:\")\n",
    "print(unemployment.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f580422f",
   "metadata": {},
   "source": [
    "**Step 3: Add Market Sentiment using GenAI Hugging Face**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbbb48c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Step 1: Load a pre-trained sentiment analysis model\n",
    "sentiment_pipeline = pipeline(\"sentiment-analysis\")\n",
    "\n",
    "# Step 2: Sample headlines or tweets about the company\n",
    "news_headlines = [\n",
    "    \"Apple beats earnings expectations with strong iPhone sales\",\n",
    "    \"Apple faces antitrust investigation in Europe\",\n",
    "    \"Analysts remain optimistic about Apple stock\",\n",
    "    \"Apple launches new product lineup with AI features\",\n",
    "    \"Supply chain disruptions may impact Apple's production\"\n",
    "]\n",
    "\n",
    "# Step 3: Run sentiment analysis on each headline\n",
    "for headline in news_headlines:\n",
    "    result = sentiment_pipeline(headline)[0]  # Get result as a dictionary\n",
    "    print(f\"'{headline}' â†’ {result['label']} (confidence: {round(result['score'], 2)})\")\n",
    "\n",
    "# Step 4 (Optional): Convert sentiment to numeric score\n",
    "sentiment_scores = []\n",
    "for headline in news_headlines:\n",
    "    result = sentiment_pipeline(headline)[0]\n",
    "    score = result['score'] if result['label'] == 'POSITIVE' else -result['score']\n",
    "    sentiment_scores.append(score)\n",
    "\n",
    "# Let's take the average score (simulate daily sentiment)\n",
    "daily_sentiment = sum(sentiment_scores) / len(sentiment_scores)\n",
    "print(f\"\\nDaily Market Sentiment Score: {round(daily_sentiment, 2)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "734879f9",
   "metadata": {},
   "source": [
    "**Step 4: Feature Engineering**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15fc1259",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove timezone from stock_df index\n",
    "stock_df.index = stock_df.index.tz_localize(None)\n",
    "\n",
    "# Already done:\n",
    "cpi.index = pd.to_datetime(cpi.index)\n",
    "interest_rate.index = pd.to_datetime(interest_rate.index)\n",
    "unemployment.index = pd.to_datetime(unemployment.index)\n",
    "\n",
    "# Now you can join them\n",
    "combined = stock_df.join(cpi, how='left')\\\n",
    "                   .join(interest_rate, how='left')\\\n",
    "                   .join(unemployment, how='left')\n",
    "\n",
    "# Rename columns for clarity\n",
    "combined.columns = ['Close', 'daily_return', 'volatility', 'sentiment', 'CPI', 'Interest_Rate', 'Unemployment']\n",
    "\n",
    "# Fill missing values (mainly for monthly econ data)\n",
    "combined.fillna(method='ffill', inplace=True)\n",
    "\n",
    "# Preview result\n",
    "print(combined.tail())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2884a514",
   "metadata": {},
   "source": [
    "**Step 5: Predict Stock Price using Prophet**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d468b6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from prophet import Prophet\n",
    "\n",
    "# Prepare the data for Prophet\n",
    "prophet_df = combined.reset_index()[['Date', 'Close']]\n",
    "prophet_df.rename(columns={'Date': 'ds', 'Close': 'y'}, inplace=True)\n",
    "\n",
    "# Drop any missing values (just in case)\n",
    "prophet_df.dropna(inplace=True)\n",
    "# Create the model\n",
    "model = Prophet()\n",
    "\n",
    "# Train the model on historical data\n",
    "model.fit(prophet_df)\n",
    "\n",
    "# Create a dataframe for future dates\n",
    "future = model.make_future_dataframe(periods=30)\n",
    "\n",
    "# Predict future values\n",
    "forecast = model.predict(future)\n",
    "\n",
    "# Show forecasted values\n",
    "forecast[['ds', 'yhat', 'yhat_lower', 'yhat_upper']].tail()\n",
    "\n",
    "fig = model.plot(forecast)\n",
    "fig2 = model.plot_components(forecast)\n",
    "forecast[['ds', 'yhat']].to_csv(\"apple_stock_forecast.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec0f2176",
   "metadata": {},
   "source": [
    "**Step 6: Predict Stock Price Using Deep Learning (Darts - LSTM Model)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018e4897",
   "metadata": {},
   "outputs": [],
   "source": [
    "from darts import TimeSeries\n",
    "from darts.models import RNNModel\n",
    "from darts.dataprocessing.transformers import Scaler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "# Ensure Date is datetime and set as index\n",
    "combined.reset_index(inplace=True)\n",
    "combined['Date'] = pd.to_datetime(combined['Date'])\n",
    "combined.set_index('Date', inplace=True)\n",
    "\n",
    "# Fix: Tell Darts to fill missing dates and infer frequency\n",
    "target_series = TimeSeries.from_series(\n",
    "    combined['Close'],\n",
    "    fill_missing_dates=True,\n",
    "    freq='D'  # 'D' means daily\n",
    ")\n",
    "\n",
    "covariate_series = TimeSeries.from_dataframe(\n",
    "    combined[['daily_return', 'volatility', 'sentiment', 'CPI', 'Interest_Rate', 'Unemployment']],\n",
    "    fill_missing_dates=True,\n",
    "    freq='D'  # same fix\n",
    ")\n",
    "\n",
    "# Normalize both target and covariates\n",
    "scaler_target = Scaler()\n",
    "scaler_covariates = Scaler()\n",
    "\n",
    "target_scaled = scaler_target.fit_transform(target_series)\n",
    "covariates_scaled = scaler_covariates.fit_transform(covariate_series)\n",
    "\n",
    "train_target, val_target = target_scaled.split_before(0.8)\n",
    "train_cov, val_cov = covariates_scaled.split_before(0.8)\n",
    "\n",
    "\n",
    "model = RNNModel(\n",
    "    model='LSTM',\n",
    "    input_chunk_length=30,   # Lookback window\n",
    "    output_chunk_length=7,   # Predict next 7 days\n",
    "    n_epochs=100,\n",
    "    random_state=42,\n",
    "    training_length=50,\n",
    "    dropout=0.2,\n",
    "    batch_size=32,\n",
    "    optimizer_kwargs={'lr': 1e-3}\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "model.fit(\n",
    "    series=train_target,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "prediction = model.predict(\n",
    "    n=30,  # Predict 30 days into the future\n",
    ")\n",
    "\n",
    "# Reverse scaling\n",
    "prediction = scaler_target.inverse_transform(prediction)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e42f6c12",
   "metadata": {},
   "source": [
    "**Step 7: Backtesting (Darts LSTM)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8317d92e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from darts.metrics import mape\n",
    "\n",
    "# Run backtest with LSTM model\n",
    "backtest = model.historical_forecasts(\n",
    "    series=target_scaled,\n",
    "    past_covariates=covariates_scaled,\n",
    "    start=0.8,                  # Start backtesting from 80% of data\n",
    "    forecast_horizon=7,         # Predict next 7 days at each step\n",
    "    stride=7,                   # Move forward in weekly steps\n",
    "    retrain=False,              # Set True to retrain each time (slower)\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Compute error\n",
    "error = mape(target_scaled, backtest)\n",
    "print(f\"MAPE (Mean Absolute Percentage Error): {round(error, 2)}%\")\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Prophet: use last N values (align with test set)\n",
    "actual = prophet_df['y'].tail(30).values\n",
    "predicted = forecast['yhat'].tail(30).values\n",
    "\n",
    "mae = mean_absolute_error(actual, predicted)\n",
    "print(f\"Prophet MAE: {mae:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92021a79",
   "metadata": {},
   "source": [
    "**Step 8: Use Langchain + LlamaIndex to Generate Insights**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f745f158",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "from llama_index.llms.groq import Groq\n",
    "from langchain.llms.base import LLM\n",
    "\n",
    "llm = Groq(\n",
    "    model=\"llama3-8b-8192\",  # Or another model you prefer\n",
    "    api_key=os.getenv(\"GROQ_API_KEY\"),\n",
    "    temperature=0.3\n",
    ")\n",
    "\n",
    "from llama_index.core import Document\n",
    "\n",
    "# Example: convert a few rows of your combined dataset\n",
    "data_sample = combined.tail(10)  # last 10 days\n",
    "\n",
    "docs = []\n",
    "for date, row in data_sample.iterrows():\n",
    "    text = f\"\"\"On {date.date()}, Apple stock closed at ${row['Close']:.2f}.\n",
    "    Daily return: {row['daily_return']:.4f}\n",
    "    Volatility: {row['volatility']:.4f}\n",
    "    Sentiment: {row['sentiment']:.2f}\n",
    "    CPI: {row['CPI']:.2f}\n",
    "    Interest Rate: {row['Interest_Rate']:.2f}\n",
    "    Unemployment: {row['Unemployment']:.2f}\"\"\"\n",
    "    \n",
    "    docs.append(Document(text=text))\n",
    "\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.core import VectorStoreIndex, Settings\n",
    "\n",
    "# Hugging Face embedding model\n",
    "embed_model = HuggingFaceEmbedding(model_name=\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# Configure LlamaIndex to use Groq + HuggingFace\n",
    "Settings.llm = llm\n",
    "Settings.embed_model = embed_model\n",
    "# Build the index with updated settings\n",
    "index = VectorStoreIndex.from_documents(docs)\n",
    "query_engine = index.as_query_engine()\n",
    "response = query_engine.query(\"Why did the model predict a drop in Apple's stock?\")\n",
    "print(response)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
